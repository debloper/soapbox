#!/usr/bin/env node

// Core modules
const fs = require('fs')
const path = require('path')

// 3rd party modules
const fm = require('gray-matter')
const args = require('yargs').argv

// Set the content directory, in order of priority
// If no `--path` was provided, use `./contents` as fallback
// @TODO: resolve & finalize config/variable names
const contents = args.path || process.env.contents || (process.cwd() + "/contents")

// Evaluate the posts directory inside contents
// @TODO: get rid of hard coded directory names
// @TODO: later we'll use same method for pages
const postsDir = contents + "/posts/"

// Generated artifacts are put in these directories
// @TODO: get rid of hard coded directory names
const distDir = process.cwd() + "/dist"
const dataDir = distDir + "/data/"

// Data for building index page (posts' list)
let postsList = []

// Now that we have the directory to read from
// Let's read files inside, and parse them too
fs.readdir(postsDir, function (err, files) {

  if (err) throw err

  // Create data directory to store JSONs,
  // Only if there're more than one files, 
  // & the directory doesn't already exist
  if (files.length && !fs.existsSync(dataDir)) {
    fs.mkdirSync(distDir, 0o775)
    fs.mkdirSync(dataDir, 0o775)
  }

  // Now, to the interesting part
  // Iterate over all the files to be parsed
  // @TODO: write a recursive file-tree-walker
  for (let file of files) {

    // Resolve full file name, for reusability
    file = [postsDir, file].join('')

    // Read & parse each file with gray-matter `read()`
    let parsed = fm.read(file)

    // Post meta-data for `postsList`
    // @TODO: the path may not be same as slug
    //        shouldn't force a convention here
    let post = {
      date: parsed.data.date,
      path: path.parse(file).name,
      title: parsed.data.title,
      summary: parsed.excerpt
    }

    // And put the post metadata in `postsList`
    postsList.push(post)

    // Derive the respective JSON file path, that is to be created
    let newFile = [dataDir, path.parse(file).name, '.json'].join('')

    // Write files to the data destination, show status
    fs.writeFile(newFile, JSON.stringify(parsed), { mode: 0o664 }, function (e) {
      if (e) throw e
      console.log(file + ' parsed to ' + newFile)
    })
  }

  // Now that we've been through all the posts, our postList is fully pupolated
  // @TODO: use some sort of ordering before writing the data to disk
  fs.writeFile((dataDir + 'index.json'), JSON.stringify(postsList), { mode: 0o664 }, function (e) {
    if (e) throw e
    console.log('List of posts written to: ' + dataDir + 'index.json')
  })
})
